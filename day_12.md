# Date = 27 June 2024
# TYPES OF MACHINE LEARNING (UNSUPERVISED LEARNING)
The goal of Day 12 was to explore about Unsupervised Learning which involves training models on data without labeled outputs. This type of learning is used to find hidden patterns, structures or groupings in the data. Common tasks within Unsupervised learning include clustering (e.g. K-Means, Hierarchical Clustering) and dimensionality reduction (PCA). By understanding Unsupervised learning techniques, I am able to analyze and interpret complex datasets, detect anomalies and uncover insights without predefined labels or categories.

---

## Introduction to Unsupervised Learning
Unsupervised Learning is a type of machine learning where the algorithm is given data without explicit labels or predefined outputs. In other words, the model is tasked with identifying patterns, structures, or relationships within the input data without any guidance on what the desired output should be. Unlike supervised learning, there are no "correct" answers provided during training. The primary goal of unsupervised learning is to explore the underlying structure of the data, to group similar data points together (clustering), reduce the dimensionality of the data, or identify anomalies or outliers.

Unsupervised learning is commonly used in scenarios where labeled data is not available or is too expensive to acquire, making it useful for data exploration and pattern recognition. For example, it can be applied to customer segmentation, anomaly detection, data compression, and feature extraction.


---

## Key Components of Unsupervised Learning

1. Input Data (Features): Similar to supervised learning, Unsupervised learning algorithms start with a dataset containing multiple features. These features describe the data points, but unlike Supervised learning, There are no predefined labels associated with the data. For instance, In a customer segmentation task, The input data could include a customer's purchase history, age, location etc.

2. No Output (No Labels): In Unsupervised learning, There is no specific output or label that the model is trying to predict. Instead, the model’s goal is to find patterns, structures or relationships within the data. For example, In a Clustering task, the model might group similar data points (e.g. Customers with similar purchasing behaviors) together without knowing beforehand how many groups (clusters) exist.

3. Model: The model in unsupervised learning aims to uncover hidden structures or patterns from the input data. Some common types of models used in unsupervised learning include clustering algorithms, dimensionality reduction techniques and anomaly detection models.

4. Loss Function: Unlike Supervised learning, Unsupervised learning may not have a straightforward loss function tied to a specific output. Instead, the effectiveness of the model is typically measured by how well it can group or organize the data. For instance, In Clustering tasks, The quality of clustering can be evaluated using metrics like intra-cluster similarity or inter-cluster distance.

5. Training Process: In Unsupervised learning,Thhe algorithm explores the data, identifies patterns or relationships and adjusts its parameters accordingly. For Clustering, this could mean partitioning the data into groups whereas for dimensionality reduction it could mean identifying the most important features that explain the variation in the data.

6. Evaluation: Since there are no labels to compare to, the evaluation of an unsupervised learning model is more challenging and often involves qualitative measures or domain-specific metrics. In clustering, evaluation could involve checking how well the clusters correspond to real-world categories or in dimensionality reduction, It could involve how well the reduced dimensions capture the variance in the data.

---

## Working of Unsupervised Learning

1. Training Data: The starting point in Unsupervised learning is the dataset that consists of input features but there are no labels or explicit outcomes to predict. The goal is to analyze these data points and uncover hidden relationships, groupings or structures. An example might be a customer database with information on their purchase history, but without any indication of whether each customer belongs to a certain market segment (e.g. high-end, budget, frequent shopper).

2. Pattern Discovery (Clustering): One common type of Unsupervised learning is clustering. The algorithm attempts to group similar data points together based on certain similarity measures. For example, In customer segmentation, a Clustering algorithm could identify distinct groups of customers with similar behaviors like customers who tend to buy luxury items versus those who purchase budget products.

3. Dimensionality Reduction: Another popular technique in Unsupervised learning is dimensionality reduction. In high-dimensional datasets (with many features), Dimensionality reduction methods can simplify the data by reducing the number of features while retaining important patterns. For example Principal Component Analysis (PCA) can reduce a dataset with thousands of variables into just a few components that capture most of the variation in the data.

4. Anomaly Detection: Unsupervised learning can also be used to detect outliers or anomalies in data. For instance, In fraud detection, An algorithm could learn the typical behavior of customers and then identify those who deviate significantly from this behavior (e.g. Unsually large purchases or purchases from foreign locations) without being explicitly told what constitutes fraud.

5. Evaluation: Evaluating the results of unsupervised learning is trickier than supervised learning since there are no "correct" labels to compare the model's outputs.Evaluation is typically based on how useful or meaningful the model's outputs are. For example, In Clustering you might evaluate the performance of a clustering algorithm by how well it groups similar items together or by how distinct the clusters are from each other. In Dimensionality reduction you evaluate how well the reduced data represents the underlying structure of the original data.



---

## Examples of Algorithms Used in Unsupervised Learning

1. K-Means Clustering: A popular clustering algorithm that groups data points into a predefined number of clusters (K). The algorithm assigns each data point to the nearest cluster center and updates the cluster centers iteratively to minimize within-cluster variance. It comes under Partitioning Clustering.

2. Hierarchical Clustering: This algorithm creates a hierarchy of clusters starting with each data point as its own cluster and progressively merging the closest clusters. It can be visualized as a dendrogram(A tree-like structure) that shows how clusters are merged at each step.

3. Principal Component Analysis (PCA): A dimensionality reduction algorithm that transforms the original data into a smaller set of uncorrelated variables (principal components) that capture the maximum variance in the data. PCA is often used to simplify complex datasets and make them easier to visualize and analyze.

---

## Today’s Learning Summary:
So Today I learned that Unsupervised learning is a powerful machine learning paradigm that allows algorithms to identify hidden patterns and structures in data without needing labeled examples. It is particularly useful for exploring large and Unlabeled datasets discovering relationships and simplifying complex data. While it can be more challenging to evaluate and interpret. Unsupervised learning techniques are widely applied in fields such as clustering, dimensionality reduction, anomaly detection and feature extraction. With the right tools and techniques Unsupervised learning can uncover valuable insights that would be difficult to obtain using other approaches.



